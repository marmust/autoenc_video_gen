{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08006c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Model\n",
    "import imageio, os\n",
    "\n",
    "run_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48baee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "RESOLUTION_WIDTH = 128\n",
    "RESOLUTION_HEIGHT = 128\n",
    "CHANNELS = 3\n",
    "BOTTLENECK_DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels=CHANNELS, latent_dim=BOTTLENECK_DIM):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(64),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(128),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(256),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(512)\n",
    "        )\n",
    "        self.encoder_fc = nn.Linear(512 * 4 * 4, latent_dim)\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 512 * 4 * 4)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (512, 4, 4)),\n",
    "            ResidualBlock(512),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(256),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(128),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(64),\n",
    "            nn.ConvTranspose2d(64, in_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.encoder_fc(x)\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_fc(z)\n",
    "        return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59577264",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = torch.load('checkpoints/run1/autoenc', map_location=run_device)\n",
    "autoenc = autoenc.to(run_device).eval()\n",
    "transformer = torch.load('checkpoints/run1/transformer', map_location=run_device)\n",
    "transformer = transformer.to(run_device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames(num_frames=600):\n",
    "    seq = torch.zeros(1, 1, BOTTLENECK_DIM, device=run_device)\n",
    "    frames = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_frames):\n",
    "            out = transformer(inputs_embeds=seq).last_hidden_state\n",
    "            next_latent = out[:, -1:, :]\n",
    "            frame = autoenc.decode(next_latent.squeeze(1)).clamp(-1, 1)\n",
    "            frames.append(frame.cpu())\n",
    "            seq = torch.cat([seq, next_latent], dim=1)\n",
    "    return frames\n",
    "\n",
    "def save_video(frames, output='output.mp4', fps=60):\n",
    "    writer = imageio.get_writer(output, fps=fps)\n",
    "    for frame in frames:\n",
    "        img = frame.squeeze(0).permute(1,2,0).numpy()\n",
    "        img = ((img + 1)/2 * 255).astype('uint8')\n",
    "        writer.append_data(img)\n",
    "    writer.close()\n",
    "    print(f'Saved {output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = generate_frames()\n",
    "save_video(frames)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
